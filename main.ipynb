{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ham\\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\\nham\\tOk lar... Joking wif u oni...\\nspam\\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\\nham\\tU dun say so early hor... U c already then say...\\nham\\tNah I don't think he goes to usf, he lives around here though\\nspam\\tFreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, Â£1.50 to rcv\\nham\\tEven my brother is not like to speak with me. They treat me like aids patent.\\nham\\tAs per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\\nspam\\tWINNER!! As a valued network customer you have been selected to receivea Â£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\\nspam\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r=open(\"SMSSpamCollection.tsv\").read() # a file that contains random text messages\n",
    "r[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                          body_text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d=pd.read_csv('SMSSpamCollection.tsv', sep= '\\t',names=['label','body_text'],header=None)\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "      <th>body_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                          body_text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                     body_text_clean  \n",
       "0  Go until jurong point crazy Available only in ...  \n",
       "1                            Ok lar Joking wif u oni  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...  \n",
       "3        U dun say so early hor U c already then say  \n",
       "4  Nah I dont think he goes to usf he lives aroun...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rem_p(text):\n",
    "    text_nop=\"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_nop\n",
    "\n",
    "d['body_text_clean']=d['body_text'].apply(lambda x: rem_p(x))\n",
    "\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=tokenize.sent_tokenize(r)  #will give us all the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=s[0:10]    #reducing the number of sentences to be stored in the dict\n",
    "p={'Sentences':ss}  # a dict with to store all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sentences': ['ham\\tGo until jurong point, crazy..',\n",
       "  'Available only in bugis n great world la e buffet... Cine there got amore wat...\\nham\\tOk lar...',\n",
       "  'Joking wif u oni...\\nspam\\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005.',\n",
       "  \"Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\\nham\\tU dun say so early hor... U c already then say...\\nham\\tNah I don't think he goes to usf, he lives around here though\\nspam\\tFreeMsg Hey there darling it's been 3 week's now and no word back!\",\n",
       "  \"I'd like some fun you up for it still?\",\n",
       "  'Tb ok!',\n",
       "  'XxX std chgs to send, Â£1.50 to rcv\\nham\\tEven my brother is not like to speak with me.',\n",
       "  'They treat me like aids patent.',\n",
       "  \"ham\\tAs per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers.\",\n",
       "  'Press *9 to copy your friends Callertune\\nspam\\tWINNER!!']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def tokenize(text):\n",
    "    tokens=re.split('\\W+',text)\n",
    "    return tokens\n",
    "d['body_text_tokenized']=d['body_text_clean'].apply(lambda x:tokenize(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "stopword=nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokenized_list):\n",
    "    text=[word for word in tokenized_list if word not in stopword]\n",
    "    return text\n",
    "d['body_text_nostop']=d['body_text_tokenized'].apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "      <th>body_text_nostop</th>\n",
       "      <th>body_text_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                          body_text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Go until jurong point crazy Available only in ...   \n",
       "1                            Ok lar Joking wif u oni   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3        U dun say so early hor U c already then say   \n",
       "4  Nah I dont think he goes to usf he lives aroun...   \n",
       "\n",
       "                                 body_text_tokenized  \\\n",
       "0  [go, until, jurong, point, crazy, available, o...   \n",
       "1                     [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, in, 2, a, wkly, comp, to, win, f...   \n",
       "3  [u, dun, say, so, early, hor, u, c, already, t...   \n",
       "4  [nah, i, dont, think, he, goes, to, usf, he, l...   \n",
       "\n",
       "                                    body_text_nostop  \\\n",
       "0  [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                     [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "3      [u, dun, say, early, hor, u, c, already, say]   \n",
       "4  [nah, dont, think, goes, usf, lives, around, t...   \n",
       "\n",
       "                                   body_text_stemmed  \n",
       "0  [go, jurong, point, crazi, avail, bugi, n, gre...  \n",
       "1                       [ok, lar, joke, wif, u, oni]  \n",
       "2  [free, entri, 2, wkli, comp, win, fa, cup, fin...  \n",
       "3      [u, dun, say, earli, hor, u, c, alreadi, say]  \n",
       "4  [nah, dont, think, goe, usf, live, around, tho...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps=nltk.PorterStemmer()\n",
    "\n",
    "def stemming(tokenized_text):\n",
    "    text=[ps.stem(word)for word in tokenized_text]\n",
    "    return text\n",
    "d['body_text_stemmed']=d['body_text_nostop'].apply(lambda x:stemming(x))\n",
    "\n",
    "d.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "st=d['body_text_stemmed'][0:5].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(st)  # list of stems for first 5 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "p['stems'] = st[2]  # reducing the number of stems in dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sentences': ['ham\\tGo until jurong point, crazy..',\n",
       "  'Available only in bugis n great world la e buffet... Cine there got amore wat...\\nham\\tOk lar...',\n",
       "  'Joking wif u oni...\\nspam\\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005.',\n",
       "  \"Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\\nham\\tU dun say so early hor... U c already then say...\\nham\\tNah I don't think he goes to usf, he lives around here though\\nspam\\tFreeMsg Hey there darling it's been 3 week's now and no word back!\",\n",
       "  \"I'd like some fun you up for it still?\",\n",
       "  'Tb ok!',\n",
       "  'XxX std chgs to send, Â£1.50 to rcv\\nham\\tEven my brother is not like to speak with me.',\n",
       "  'They treat me like aids patent.',\n",
       "  \"ham\\tAs per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers.\",\n",
       "  'Press *9 to copy your friends Callertune\\nspam\\tWINNER!!'],\n",
       " 'stems': ['free',\n",
       "  'entri',\n",
       "  '2',\n",
       "  'wkli',\n",
       "  'comp',\n",
       "  'win',\n",
       "  'fa',\n",
       "  'cup',\n",
       "  'final',\n",
       "  'tkt',\n",
       "  '21st',\n",
       "  'may',\n",
       "  '2005',\n",
       "  'text',\n",
       "  'fa',\n",
       "  '87121',\n",
       "  'receiv',\n",
       "  'entri',\n",
       "  'questionstd',\n",
       "  'txt',\n",
       "  'ratetc',\n",
       "  'appli',\n",
       "  '08452810075over18']}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "      <th>body_text_nostop</th>\n",
       "      <th>body_text_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                          body_text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Go until jurong point crazy Available only in ...   \n",
       "1                            Ok lar Joking wif u oni   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3        U dun say so early hor U c already then say   \n",
       "4  Nah I dont think he goes to usf he lives aroun...   \n",
       "\n",
       "                                 body_text_tokenized  \\\n",
       "0  [go, until, jurong, point, crazy, available, o...   \n",
       "1                     [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, in, 2, a, wkly, comp, to, win, f...   \n",
       "3  [u, dun, say, so, early, hor, u, c, already, t...   \n",
       "4  [nah, i, dont, think, he, goes, to, usf, he, l...   \n",
       "\n",
       "                                    body_text_nostop  \\\n",
       "0  [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                     [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "3      [u, dun, say, early, hor, u, c, already, say]   \n",
       "4  [nah, dont, think, goes, usf, lives, around, t...   \n",
       "\n",
       "                                   body_text_stemmed  \n",
       "0  [go, jurong, point, crazi, avail, bugi, n, gre...  \n",
       "1                       [ok, lar, joke, wif, u, oni]  \n",
       "2  [free, entri, 2, wkli, comp, win, fa, cup, fin...  \n",
       "3      [u, dun, say, earli, hor, u, c, alreadi, say]  \n",
       "4  [nah, dont, think, goe, usf, live, around, tho...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn=nltk.WordNetLemmatizer()\n",
    "def lemmatizing(tokenized_text):\n",
    "    text=[wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text\n",
    "d['body_text_lemmatized']=d['body_text_nostop'].apply(lambda x:lemmatizing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=d['body_text_lemmatized'][0:2].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['go',\n",
       "  'jurong',\n",
       "  'point',\n",
       "  'crazy',\n",
       "  'available',\n",
       "  'bugis',\n",
       "  'n',\n",
       "  'great',\n",
       "  'world',\n",
       "  'la',\n",
       "  'e',\n",
       "  'buffet',\n",
       "  'cine',\n",
       "  'got',\n",
       "  'amore',\n",
       "  'wat'],\n",
       " ['ok', 'lar', 'joking', 'wif', 'u', 'oni']]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sentences': ['ham\\tGo until jurong point, crazy..',\n",
       "  'Available only in bugis n great world la e buffet... Cine there got amore wat...\\nham\\tOk lar...',\n",
       "  'Joking wif u oni...\\nspam\\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005.',\n",
       "  \"Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\\nham\\tU dun say so early hor... U c already then say...\\nham\\tNah I don't think he goes to usf, he lives around here though\\nspam\\tFreeMsg Hey there darling it's been 3 week's now and no word back!\",\n",
       "  \"I'd like some fun you up for it still?\",\n",
       "  'Tb ok!',\n",
       "  'XxX std chgs to send, Â£1.50 to rcv\\nham\\tEven my brother is not like to speak with me.',\n",
       "  'They treat me like aids patent.',\n",
       "  \"ham\\tAs per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers.\",\n",
       "  'Press *9 to copy your friends Callertune\\nspam\\tWINNER!!'],\n",
       " 'stems': ['free',\n",
       "  'entri',\n",
       "  '2',\n",
       "  'wkli',\n",
       "  'comp',\n",
       "  'win',\n",
       "  'fa',\n",
       "  'cup',\n",
       "  'final',\n",
       "  'tkt',\n",
       "  '21st',\n",
       "  'may',\n",
       "  '2005',\n",
       "  'text',\n",
       "  'fa',\n",
       "  '87121',\n",
       "  'receiv',\n",
       "  'entri',\n",
       "  'questionstd',\n",
       "  'txt',\n",
       "  'ratetc',\n",
       "  'appli',\n",
       "  '08452810075over18'],\n",
       " 'lemma': [['go',\n",
       "   'jurong',\n",
       "   'point',\n",
       "   'crazy',\n",
       "   'available',\n",
       "   'bugis',\n",
       "   'n',\n",
       "   'great',\n",
       "   'world',\n",
       "   'la',\n",
       "   'e',\n",
       "   'buffet',\n",
       "   'cine',\n",
       "   'got',\n",
       "   'amore',\n",
       "   'wat'],\n",
       "  ['ok', 'lar', 'joking', 'wif', 'u', 'oni']]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p['lemma']=l\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summa import summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=(summarizer.summarize(r[0:10000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ham\\tOk lar...\\nham\\tU dun say so early hor...\\nham\\tEven my brother is not like to speak with me.\\nham\\tI'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k?\\nham\\tI've been searching for the right words to thank you for this breather.\\nham\\tOh k...i'm watching here:)\\nham\\tEh u remember how 2 spell his name...\\nham\\tFine if thatÂ’s the way u feel.\\nham\\tFfffffffff.\\nham\\tLol your always so convincing.\\nham\\tDid you catch the bus ?\\nham\\tAhhh.\\nham\\tYeah he got in at 2 and was v apologetic.\\nham\\tK tell me anything about you.\\nham\\tYup...\\nham\\tAnything lor...\\nham\\tHello!\\nham\\tDid I forget to tell you ?\\nham\\tWHO ARE YOU SEEING?\\nham\\tGreat!\\nham\\tFair enough, anything going on?\\nham\\tU don't know how stubborn I am.\\nham\\tWhat you thinked about me.\\nham\\tSorry, I'll call later in meeting.\\nham\\tTell where you reached\\nham\\tIts a part of checking IQ\\nham\\tOk lar i double check wif da hair dresser already he said wun cut v short.\\nham\\tI plane to give on this month end.\\nham\\tFinished class where are you.\\nham\\tU can call me now...\\nham\\tI am waiting machan.\\nham\\tDoes not operate after  &lt;#&gt;  or what\\nham\\tIts not the same here.\\nham\\tSorry, I'll call later\\nham\\tK.\\nham\\tYou will be in the place of that man\\nham\\tI call you later, don't have network.\\nham\\tFor real when u getting on yo?\\nham\\tYes I started to send requests to make it but pain came back so I'm back in bed.\\nham\\tI'm really not up to it still tonight babe\\nham\\tEla kano.,il download, come wen ur free..\\nham\\tYeah do!\\nham\\tSorry to be a pain.\\nham\\ti see.\\nham\\tPlease don't text me anymore.\\nham\\tI'm still looking for a car to buy.\\nham\\twow.\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "p['Summary']=summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sentences': ['ham\\tGo until jurong point, crazy..',\n",
       "  'Available only in bugis n great world la e buffet... Cine there got amore wat...\\nham\\tOk lar...',\n",
       "  'Joking wif u oni...\\nspam\\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005.',\n",
       "  \"Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\\nham\\tU dun say so early hor... U c already then say...\\nham\\tNah I don't think he goes to usf, he lives around here though\\nspam\\tFreeMsg Hey there darling it's been 3 week's now and no word back!\",\n",
       "  \"I'd like some fun you up for it still?\",\n",
       "  'Tb ok!',\n",
       "  'XxX std chgs to send, Â£1.50 to rcv\\nham\\tEven my brother is not like to speak with me.',\n",
       "  'They treat me like aids patent.',\n",
       "  \"ham\\tAs per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers.\",\n",
       "  'Press *9 to copy your friends Callertune\\nspam\\tWINNER!!'],\n",
       " 'stems': ['free',\n",
       "  'entri',\n",
       "  '2',\n",
       "  'wkli',\n",
       "  'comp',\n",
       "  'win',\n",
       "  'fa',\n",
       "  'cup',\n",
       "  'final',\n",
       "  'tkt',\n",
       "  '21st',\n",
       "  'may',\n",
       "  '2005',\n",
       "  'text',\n",
       "  'fa',\n",
       "  '87121',\n",
       "  'receiv',\n",
       "  'entri',\n",
       "  'questionstd',\n",
       "  'txt',\n",
       "  'ratetc',\n",
       "  'appli',\n",
       "  '08452810075over18'],\n",
       " 'lemma': [['go',\n",
       "   'jurong',\n",
       "   'point',\n",
       "   'crazy',\n",
       "   'available',\n",
       "   'bugis',\n",
       "   'n',\n",
       "   'great',\n",
       "   'world',\n",
       "   'la',\n",
       "   'e',\n",
       "   'buffet',\n",
       "   'cine',\n",
       "   'got',\n",
       "   'amore',\n",
       "   'wat'],\n",
       "  ['ok', 'lar', 'joking', 'wif', 'u', 'oni']],\n",
       " 'Summary': \"ham\\tOk lar...\\nham\\tU dun say so early hor...\\nham\\tEven my brother is not like to speak with me.\\nham\\tI'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k?\\nham\\tI've been searching for the right words to thank you for this breather.\\nham\\tOh k...i'm watching here:)\\nham\\tEh u remember how 2 spell his name...\\nham\\tFine if thatÂ’s the way u feel.\\nham\\tFfffffffff.\\nham\\tLol your always so convincing.\\nham\\tDid you catch the bus ?\\nham\\tAhhh.\\nham\\tYeah he got in at 2 and was v apologetic.\\nham\\tK tell me anything about you.\\nham\\tYup...\\nham\\tAnything lor...\\nham\\tHello!\\nham\\tDid I forget to tell you ?\\nham\\tWHO ARE YOU SEEING?\\nham\\tGreat!\\nham\\tFair enough, anything going on?\\nham\\tU don't know how stubborn I am.\\nham\\tWhat you thinked about me.\\nham\\tSorry, I'll call later in meeting.\\nham\\tTell where you reached\\nham\\tIts a part of checking IQ\\nham\\tOk lar i double check wif da hair dresser already he said wun cut v short.\\nham\\tI plane to give on this month end.\\nham\\tFinished class where are you.\\nham\\tU can call me now...\\nham\\tI am waiting machan.\\nham\\tDoes not operate after  &lt;#&gt;  or what\\nham\\tIts not the same here.\\nham\\tSorry, I'll call later\\nham\\tK.\\nham\\tYou will be in the place of that man\\nham\\tI call you later, don't have network.\\nham\\tFor real when u getting on yo?\\nham\\tYes I started to send requests to make it but pain came back so I'm back in bed.\\nham\\tI'm really not up to it still tonight babe\\nham\\tEla kano.,il download, come wen ur free..\\nham\\tYeah do!\\nham\\tSorry to be a pain.\\nham\\ti see.\\nham\\tPlease don't text me anymore.\\nham\\tI'm still looking for a car to buy.\\nham\\twow.\"}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun=[]\n",
    "ss=s[0:1000]   #to reduce the number of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "for sentence in ss:\n",
    "    for word,pos in nltk.pos_tag(nltk.word_tokenize(str(sentence))):\n",
    "         if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'):\n",
    "             noun.append(word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb=[]\n",
    "for sentence in ss:\n",
    "    for word,pos in nltk.pos_tag(nltk.word_tokenize(str(sentence))):\n",
    "         if (pos == 'VB' or pos == 'VDB' or pos == 'VBG' or pos == 'VBN' or pos =='VBP' or pos =='VBZ'):\n",
    "             verb.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "p['Nouns']=noun[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "p['Verb']=verb[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sentences': ['ham\\tGo until jurong point, crazy..',\n",
       "  'Available only in bugis n great world la e buffet... Cine there got amore wat...\\nham\\tOk lar...',\n",
       "  'Joking wif u oni...\\nspam\\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005.',\n",
       "  \"Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\\nham\\tU dun say so early hor... U c already then say...\\nham\\tNah I don't think he goes to usf, he lives around here though\\nspam\\tFreeMsg Hey there darling it's been 3 week's now and no word back!\",\n",
       "  \"I'd like some fun you up for it still?\",\n",
       "  'Tb ok!',\n",
       "  'XxX std chgs to send, Â£1.50 to rcv\\nham\\tEven my brother is not like to speak with me.',\n",
       "  'They treat me like aids patent.',\n",
       "  \"ham\\tAs per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers.\",\n",
       "  'Press *9 to copy your friends Callertune\\nspam\\tWINNER!!'],\n",
       " 'stems': ['free',\n",
       "  'entri',\n",
       "  '2',\n",
       "  'wkli',\n",
       "  'comp',\n",
       "  'win',\n",
       "  'fa',\n",
       "  'cup',\n",
       "  'final',\n",
       "  'tkt',\n",
       "  '21st',\n",
       "  'may',\n",
       "  '2005',\n",
       "  'text',\n",
       "  'fa',\n",
       "  '87121',\n",
       "  'receiv',\n",
       "  'entri',\n",
       "  'questionstd',\n",
       "  'txt',\n",
       "  'ratetc',\n",
       "  'appli',\n",
       "  '08452810075over18'],\n",
       " 'lemma': [['go',\n",
       "   'jurong',\n",
       "   'point',\n",
       "   'crazy',\n",
       "   'available',\n",
       "   'bugis',\n",
       "   'n',\n",
       "   'great',\n",
       "   'world',\n",
       "   'la',\n",
       "   'e',\n",
       "   'buffet',\n",
       "   'cine',\n",
       "   'got',\n",
       "   'amore',\n",
       "   'wat'],\n",
       "  ['ok', 'lar', 'joking', 'wif', 'u', 'oni']],\n",
       " 'Summary': \"ham\\tOk lar...\\nham\\tU dun say so early hor...\\nham\\tEven my brother is not like to speak with me.\\nham\\tI'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k?\\nham\\tI've been searching for the right words to thank you for this breather.\\nham\\tOh k...i'm watching here:)\\nham\\tEh u remember how 2 spell his name...\\nham\\tFine if thatÂ’s the way u feel.\\nham\\tFfffffffff.\\nham\\tLol your always so convincing.\\nham\\tDid you catch the bus ?\\nham\\tAhhh.\\nham\\tYeah he got in at 2 and was v apologetic.\\nham\\tK tell me anything about you.\\nham\\tYup...\\nham\\tAnything lor...\\nham\\tHello!\\nham\\tDid I forget to tell you ?\\nham\\tWHO ARE YOU SEEING?\\nham\\tGreat!\\nham\\tFair enough, anything going on?\\nham\\tU don't know how stubborn I am.\\nham\\tWhat you thinked about me.\\nham\\tSorry, I'll call later in meeting.\\nham\\tTell where you reached\\nham\\tIts a part of checking IQ\\nham\\tOk lar i double check wif da hair dresser already he said wun cut v short.\\nham\\tI plane to give on this month end.\\nham\\tFinished class where are you.\\nham\\tU can call me now...\\nham\\tI am waiting machan.\\nham\\tDoes not operate after  &lt;#&gt;  or what\\nham\\tIts not the same here.\\nham\\tSorry, I'll call later\\nham\\tK.\\nham\\tYou will be in the place of that man\\nham\\tI call you later, don't have network.\\nham\\tFor real when u getting on yo?\\nham\\tYes I started to send requests to make it but pain came back so I'm back in bed.\\nham\\tI'm really not up to it still tonight babe\\nham\\tEla kano.,il download, come wen ur free..\\nham\\tYeah do!\\nham\\tSorry to be a pain.\\nham\\ti see.\\nham\\tPlease don't text me anymore.\\nham\\tI'm still looking for a car to buy.\\nham\\twow.\",\n",
       " 'Nouns': ['ham',\n",
       "  'Go',\n",
       "  'point',\n",
       "  'crazy..',\n",
       "  'bugis',\n",
       "  'world',\n",
       "  'la',\n",
       "  'buffet',\n",
       "  'Cine',\n",
       "  'ham',\n",
       "  'Ok',\n",
       "  'lar',\n",
       "  'wif',\n",
       "  'oni',\n",
       "  'entry',\n",
       "  'comp',\n",
       "  'FA',\n",
       "  'Cup',\n",
       "  'tkts',\n",
       "  'May',\n",
       "  'Text',\n",
       "  'FA',\n",
       "  'entry',\n",
       "  'question',\n",
       "  'txt',\n",
       "  'rate',\n",
       "  'T',\n",
       "  'C',\n",
       "  'apply',\n",
       "  'ham',\n",
       "  'U',\n",
       "  'dun',\n",
       "  'hor',\n",
       "  'U',\n",
       "  'Nah',\n",
       "  'FreeMsg',\n",
       "  'Hey',\n",
       "  'week',\n",
       "  'word',\n",
       "  'fun',\n",
       "  'Tb',\n",
       "  'ok',\n",
       "  'XxX',\n",
       "  'std',\n",
       "  'chgs',\n",
       "  'ham',\n",
       "  'brother',\n",
       "  'aids',\n",
       "  'patent',\n",
       "  'ham'],\n",
       " 'Verb': ['Joking',\n",
       "  'win',\n",
       "  'receive',\n",
       "  'say',\n",
       "  'c',\n",
       "  'say',\n",
       "  'do',\n",
       "  'think',\n",
       "  'goes',\n",
       "  'usf',\n",
       "  'lives',\n",
       "  'darling',\n",
       "  \"'s\",\n",
       "  'been',\n",
       "  'like',\n",
       "  'send',\n",
       "  'Â£1.50',\n",
       "  'rcv',\n",
       "  'is',\n",
       "  'speak',\n",
       "  'treat',\n",
       "  'has',\n",
       "  'been',\n",
       "  'set',\n",
       "  'copy',\n",
       "  'valued',\n",
       "  'have',\n",
       "  'been',\n",
       "  'selected',\n",
       "  'receivea',\n",
       "  'prize',\n",
       "  'claim',\n",
       "  'Update',\n",
       "  'Call',\n",
       "  \"'m\",\n",
       "  'gon',\n",
       "  'be',\n",
       "  'home',\n",
       "  'i',\n",
       "  'do',\n",
       "  'want',\n",
       "  'talk',\n",
       "  \"'ve\",\n",
       "  'cried',\n",
       "  'win',\n",
       "  'send',\n",
       "  'have',\n",
       "  'won',\n",
       "  'Txt',\n",
       "  \"'ve\"]}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('result.json', 'w') as fp:\n",
    "    json.dump(p, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
